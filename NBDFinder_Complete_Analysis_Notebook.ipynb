{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "# NBDFinder Complete Analysis Notebook",
     "## Comprehensive Non-B DNA Motif Detection and Analysis Platform",
     "",
     "---",
     "",
     "**Author:** Dr. Venkata Rajesh Yella  ",
     "**Version:** 2.0.0  ",
     "**Date:** 2024  ",
     "**License:** Academic Use  ",
     "",
     "---",
     "",
     "### \ud83e\uddec Overview",
     "",
     "This comprehensive Jupyter notebook consolidates the entire NBDFinder codebase into a single, fully runnable and interactive analysis platform. NBDFinder is the most advanced non-B DNA prediction platform, capable of detecting and analyzing 10 major categories of non-B DNA structures:",
     "",
     "1. **Curved DNA** - DNA bending and curvature",
     "2. **Slipped DNA** - Repeat-induced slippage structures",
     "3. **Cruciform DNA** - Four-way junction structures",
     "4. **R-loop** - RNA-DNA hybrid structures",
     "5. **Triplex DNA** - Three-stranded DNA structures",
     "6. **G-Quadruplex Family** - Four-stranded G-rich structures",
     "7. **i-motif Family** - C-rich tetraplex structures",
     "8. **Z-DNA** - Left-handed DNA double helix",
     "9. **Hybrid Structures** - Complex multi-type structures",
     "10. **Non-B DNA Cluster Regions** - Hotspot regions with multiple motifs",
     "",
     "### \ud83d\udd2c Key Features",
     "",
     "- **Complete Motif Detection Pipeline**: All 10 non-B DNA structure categories",
     "- **Sequence I/O**: FASTA parsing, multi-sequence support, NCBI fetching",
     "- **Advanced Visualization**: Publication-quality plots, heatmaps, interactive figures",
     "- **Clinical Analysis**: Disease variant detection, pathogenicity scoring, ACMG guidelines",
     "- **Comparative Genomics**: Bacterial genome analysis and comparison",
     "- **Machine Learning**: AI-enhanced motif prediction and scoring",
     "- **Conservation Analysis**: Evolutionary sequence conservation",
     "- **Multi-format Export**: CSV, Excel, TXT, and JSON outputs",
     "",
     "### \ud83d\udcda Educational Value",
     "",
     "This notebook serves as both a research tool and educational resource, providing:",
     "- Step-by-step documentation of analysis workflows",
     "- Scientific background for each motif type",
     "- Runnable examples with real genomic data",
     "- Best practices for non-B DNA analysis",
     "- Publication-ready visualization templates",
     "",
     "### \ud83d\ude80 Getting Started",
     "",
     "Run the cells sequentially to:",
     "1. Install and import all required dependencies",
     "2. Load and configure the analysis environment",
     "3. Analyze example sequences or your own data",
     "4. Generate comprehensive reports and visualizations",
     "5. Export results in multiple formats",
     "",
     "---"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 1. Dependencies and Environment Setup",
     "",
     "### \ud83d\udce6 Required Dependencies",
     "",
     "This section installs and imports all necessary packages for the complete NBDFinder analysis platform."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Install required packages (run only if packages are missing)",
     "import subprocess",
     "import sys",
     "",
     "def install_package(package):",
     "    \"\"\"Install a package using pip\"\"\"",
     "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])",
     "",
     "# Core scientific computing packages",
     "required_packages = [",
     "    \"pandas>=2.0.0\",",
     "    \"numpy>=1.24.0\", ",
     "    \"scipy>=1.10.0\",",
     "    \"matplotlib>=3.6.0\",",
     "    \"plotly>=5.15.0\",",
     "    \"seaborn>=0.12.0\",",
     "    \"biopython>=1.81\",",
     "    \"openpyxl>=3.1.0\",",
     "    \"xlsxwriter>=3.0.0\",",
     "    \"requests>=2.28.0\",",
     "    \"kaleido>=0.2.1\",",
     "    \"scikit-learn>=1.3.0\"",
     "]",
     "",
     "# Uncomment the following lines if you need to install packages",
     "# for package in required_packages:",
     "#     try:",
     "#         install_package(package)",
     "#         print(f\"\u2705 Installed {package}\")",
     "#     except Exception as e:",
     "#         print(f\"\u26a0\ufe0f Could not install {package}: {e}\")",
     "",
     "print(\"\ud83d\udce6 Package installation check complete\")"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Core Python libraries",
     "import os",
     "import sys",
     "import re",
     "import time",
     "import json",
     "import hashlib",
     "import warnings",
     "from datetime import datetime",
     "from pathlib import Path",
     "from collections import Counter, defaultdict",
     "from typing import Dict, List, Tuple, Optional, Union",
     "from io import BytesIO, StringIO",
     "",
     "# Scientific computing",
     "import numpy as np",
     "import pandas as pd",
     "from scipy import stats",
     "from scipy.stats import chi2_contingency",
     "from sklearn.preprocessing import StandardScaler",
     "from sklearn.ensemble import RandomForestClassifier",
     "from sklearn.metrics import classification_report",
     "",
     "# Visualization",
     "import matplotlib.pyplot as plt",
     "import matplotlib.patches as patches",
     "import seaborn as sns",
     "import plotly.express as px",
     "import plotly.graph_objects as go",
     "from plotly.subplots import make_subplots",
     "import plotly.figure_factory as ff",
     "",
     "# Bioinformatics",
     "try:",
     "    from Bio import Entrez, SeqIO",
     "    from Bio.Seq import Seq",
     "    from Bio.SeqUtils import GC",
     "    BIOPYTHON_AVAILABLE = True",
     "except ImportError:",
     "    print(\"\u26a0\ufe0f BioPython not available - NCBI functionality will be limited\")",
     "    BIOPYTHON_AVAILABLE = False",
     "",
     "# File handling",
     "import requests",
     "",
     "# Configure display settings",
     "pd.set_option('display.max_columns', None)",
     "pd.set_option('display.width', 1000)",
     "plt.style.use('default')",
     "sns.set_palette(\"husl\")",
     "warnings.filterwarnings('ignore')",
     "",
     "print(\"\u2705 Core libraries imported successfully\")",
     "print(f\"\ud83d\udcca Pandas version: {pd.__version__}\")",
     "print(f\"\ud83d\udd22 NumPy version: {np.__version__}\")",
     "print(f\"\ud83d\udcc8 Matplotlib version: {plt.__version__}\")",
     "print(f\"\ud83e\uddec BioPython available: {BIOPYTHON_AVAILABLE}\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 2. NBDFinder Core Module Integration",
     "",
     "### \ud83e\uddec Loading NBDFinder Motif Detection System",
     "",
     "This section integrates the complete NBDFinder motif detection pipeline, including all 10 categories of non-B DNA structures."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Add current directory to path for NBDFinder modules",
     "current_dir = os.getcwd()",
     "if current_dir not in sys.path:",
     "    sys.path.insert(0, current_dir)",
     "",
     "# Core NBDFinder imports",
     "try:",
     "    # Import all motif detection functions",
     "    from motifs import (",
     "        # Main analysis function",
     "        all_motifs, format_motif_rows,",
     "        ",
     "        # Sequence utilities",
     "        parse_fasta, parse_fasta_multi, gc_content, reverse_complement,",
     "        wrap, is_palindrome, overlapping_finditer,",
     "        ",
     "        # Category 1: Curved DNA",
     "        find_curved_DNA, curvature_score, find_polyA_polyT_tracts,",
     "        ",
     "        # Category 2: Hairpin and Cruciform",
     "        find_cruciform,",
     "        ",
     "        # Category 3: Slipped DNA",
     "        find_slipped_dna,",
     "        ",
     "        # Category 4: Triplex DNA",
     "        find_hdna, find_sticky_dna,",
     "        ",
     "        # Category 5: R-loop",
     "        find_rlfs, find_rez_advanced,",
     "        ",
     "        # Category 6: Z-DNA and eGZ",
     "        find_zdna, find_egz_motif,",
     "        ",
     "        # Category 7: i-motif and AC-motif",
     "        find_imotif, find_ac_motifs,",
     "        ",
     "        # Category 8: G4 related",
     "        find_gquadruplex, find_relaxed_gquadruplex, find_bulged_gquadruplex,",
     "        find_gtriplex, g4hunter_score,",
     "        ",
     "        # Category 9: Hybrid",
     "        find_hybrids,",
     "        ",
     "        # Category 10: Clusters",
     "        find_hotspots, merge_hotspots",
     "    )",
     "    print(\"\u2705 NBDFinder core motif detection modules loaded\")",
     "    ",
     "except ImportError as e:",
     "    print(f\"\u274c Error importing NBDFinder modules: {e}\")",
     "    print(\"Please ensure you're running this notebook from the NBDFinder directory\")",
     "    ",
     "# Import additional analysis modules",
     "try:",
     "    # Disease/clinical analysis",
     "    from disease_motifs import AdvancedDiseaseDetector",
     "    print(\"\u2705 Disease motif analysis module loaded\")",
     "    ",
     "    # Machine learning integration",
     "    from ml_predictor import AdvancedMLPredictor, enhance_motif_with_ml",
     "    print(\"\u2705 Machine learning prediction module loaded\")",
     "    ",
     "    # Bacterial genome analysis",
     "    from bacterial_genome_analysis import BacterialGenomeAnalyzer",
     "    print(\"\u2705 Bacterial genome analysis module loaded\")",
     "    ",
     "    # Visualization modules",
     "    from publication_visualizations import PublicationVisualizer",
     "    from advanced_visualization import AdvancedMotifVisualizer",
     "    print(\"\u2705 Advanced visualization modules loaded\")",
     "    ",
     "except ImportError as e:",
     "    print(f\"\u26a0\ufe0f Some advanced modules not available: {e}\")",
     "    print(\"Core functionality will still work\")",
     "",
     "print(\"\\n\ud83c\udfaf NBDFinder Analysis Platform Ready!\")",
     "print(\"\ud83d\udccb Available analysis categories:\")",
     "categories = [",
     "    \"1. Curved DNA\", \"2. Slipped DNA\", \"3. Cruciform DNA\", \"4. R-loop\", \"5. Triplex\",",
     "    \"6. G-Quadruplex Family\", \"7. i-motif Family\", \"8. Z-DNA\", \"9. Hybrid Structures\", ",
     "    \"10. Non-B DNA Clusters\"",
     "]",
     "for category in categories:",
     "    print(f\"   \u2022 {category}\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 3. Sequence Input/Output Functions",
     "",
     "### \ud83d\udcc4 FASTA Parsing and Multi-Sequence Support",
     "",
     "Comprehensive sequence handling with support for:",
     "- Single and multi-FASTA files",
     "- NCBI sequence fetching",
     "- Sequence validation and preprocessing"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class NBDFinderSequenceManager:",
     "    \"\"\"Comprehensive sequence management for NBDFinder analysis\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.sequences = []",
     "        self.sequence_names = []",
     "        self.sequence_metadata = []",
     "        ",
     "    def load_fasta_file(self, file_path: str) -> int:",
     "        \"\"\"Load sequences from a FASTA file\"\"\"",
     "        try:",
     "            with open(file_path, 'r') as f:",
     "                content = f.read()",
     "            ",
     "            sequences, names = parse_fasta_multi(content)",
     "            ",
     "            for seq, name in zip(sequences, names):",
     "                self.add_sequence(seq, name, {'source': 'file', 'file_path': file_path})",
     "            ",
     "            print(f\"\u2705 Loaded {len(sequences)} sequences from {file_path}\")",
     "            return len(sequences)",
     "            ",
     "        except Exception as e:",
     "            print(f\"\u274c Error loading FASTA file: {e}\")",
     "            return 0",
     "    ",
     "    def load_fasta_string(self, fasta_content: str) -> int:",
     "        \"\"\"Load sequences from FASTA string content\"\"\"",
     "        try:",
     "            sequences, names = parse_fasta_multi(fasta_content)",
     "            ",
     "            for seq, name in zip(sequences, names):",
     "                self.add_sequence(seq, name, {'source': 'string'})",
     "            ",
     "            print(f\"\u2705 Loaded {len(sequences)} sequences from string input\")",
     "            return len(sequences)",
     "            ",
     "        except Exception as e:",
     "            print(f\"\u274c Error parsing FASTA string: {e}\")",
     "            return 0",
     "    ",
     "    def fetch_ncbi_sequence(self, accession: str, email: str = \"user@example.com\") -> bool:",
     "        \"\"\"Fetch sequence from NCBI using accession number\"\"\"",
     "        if not BIOPYTHON_AVAILABLE:",
     "            print(\"\u274c BioPython required for NCBI fetching\")",
     "            return False",
     "            ",
     "        try:",
     "            # Set email for NCBI",
     "            Entrez.email = email",
     "            ",
     "            # Fetch sequence",
     "            handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")",
     "            record = SeqIO.read(handle, \"fasta\")",
     "            handle.close()",
     "            ",
     "            # Add to sequences",
     "            sequence = str(record.seq).upper()",
     "            name = f\"{accession}_{record.description[:50]}\"",
     "            metadata = {",
     "                'source': 'ncbi',",
     "                'accession': accession,",
     "                'description': record.description,",
     "                'length': len(sequence)",
     "            }",
     "            ",
     "            self.add_sequence(sequence, name, metadata)",
     "            print(f\"\u2705 Fetched sequence {accession} from NCBI ({len(sequence)} bp)\")",
     "            return True",
     "            ",
     "        except Exception as e:",
     "            print(f\"\u274c Error fetching NCBI sequence {accession}: {e}\")",
     "            return False",
     "    ",
     "    def add_sequence(self, sequence: str, name: str, metadata: dict = None):",
     "        \"\"\"Add a sequence to the manager\"\"\"",
     "        # Clean and validate sequence",
     "        clean_seq = sequence.upper().replace(' ', '').replace('\\n', '').replace('U', 'T')",
     "        ",
     "        # Validate sequence contains only valid nucleotides",
     "        valid_nucleotides = set('ATCGRYSWKMBDHVN')",
     "        if not set(clean_seq).issubset(valid_nucleotides):",
     "            print(f\"\u26a0\ufe0f Warning: Sequence {name} contains invalid nucleotides\")",
     "        ",
     "        self.sequences.append(clean_seq)",
     "        self.sequence_names.append(name)",
     "        ",
     "        if metadata is None:",
     "            metadata = {}",
     "        metadata.update({",
     "            'length': len(clean_seq),",
     "            'gc_content': gc_content(clean_seq),",
     "            'added_time': datetime.now().isoformat()",
     "        })",
     "        self.sequence_metadata.append(metadata)",
     "        ",
     "    def get_sequence_summary(self) -> pd.DataFrame:",
     "        \"\"\"Get summary of all loaded sequences\"\"\"",
     "        summary_data = []",
     "        for i, (seq, name, meta) in enumerate(zip(self.sequences, self.sequence_names, self.sequence_metadata)):",
     "            summary_data.append({",
     "                'Index': i,",
     "                'Name': name,",
     "                'Length (bp)': len(seq),",
     "                'GC Content (%)': round(meta.get('gc_content', 0), 2),",
     "                'Source': meta.get('source', 'unknown'),",
     "                'A Count': seq.count('A'),",
     "                'T Count': seq.count('T'),",
     "                'G Count': seq.count('G'),",
     "                'C Count': seq.count('C'),",
     "                'N Count': seq.count('N')",
     "            })",
     "        ",
     "        return pd.DataFrame(summary_data)",
     "    ",
     "    def clear_sequences(self):",
     "        \"\"\"Clear all loaded sequences\"\"\"",
     "        self.sequences = []",
     "        self.sequence_names = []",
     "        self.sequence_metadata = []",
     "        print(\"\ud83d\uddd1\ufe0f Cleared all sequences\")",
     "",
     "# Initialize sequence manager",
     "seq_manager = NBDFinderSequenceManager()",
     "print(\"\u2705 Sequence manager initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### \ud83d\udcca Load Example Sequences",
     "",
     "Load the provided example sequences to demonstrate NBDFinder capabilities."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Load example sequences from the repository",
     "example_files = [",
     "    \"example_inputs/g4_rich_sequence.fasta\",",
     "    \"example_inputs/disease_repeats.fasta\",",
     "    \"example_inputs/structural_motifs.fasta\",",
     "    \"example_inputs/comprehensive_example.fasta\"",
     "]",
     "",
     "loaded_files = []",
     "for file_path in example_files:",
     "    if os.path.exists(file_path):",
     "        count = seq_manager.load_fasta_file(file_path)",
     "        if count > 0:",
     "            loaded_files.append(file_path)",
     "    else:",
     "        print(f\"\u26a0\ufe0f Example file not found: {file_path}\")",
     "",
     "# Display sequence summary",
     "if seq_manager.sequences:",
     "    print(f\"\\n\ud83d\udccb Loaded sequences summary:\")",
     "    summary_df = seq_manager.get_sequence_summary()",
     "    display(summary_df)",
     "    ",
     "    print(f\"\\n\ud83d\udcca Quick statistics:\")",
     "    print(f\"   \u2022 Total sequences: {len(seq_manager.sequences)}\")",
     "    print(f\"   \u2022 Total nucleotides: {sum(len(seq) for seq in seq_manager.sequences):,}\")",
     "    print(f\"   \u2022 Average length: {np.mean([len(seq) for seq in seq_manager.sequences]):.0f} bp\")",
     "    print(f\"   \u2022 Average GC content: {np.mean([meta['gc_content'] for meta in seq_manager.sequence_metadata]):.1f}%\")",
     "else:",
     "    print(\"\ud83d\udd0d No example sequences found. You can still add your own sequences below.\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### \u2795 Add Your Own Sequences",
     "",
     "Use this section to add your own sequences for analysis."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Add custom sequences here",
     "",
     "# Example 1: Add a sequence directly",
     "# custom_sequence = \"ATCGATCGATCG\"  # Replace with your sequence",
     "# seq_manager.add_sequence(custom_sequence, \"My_Custom_Sequence\")",
     "",
     "# Example 2: Add sequences from FASTA string",
     "# fasta_string = \"\"\"",
     "# >Example_Sequence_1",
     "# ATCGATCGATCGATCG",
     "# >Example_Sequence_2  ",
     "# GCTAGCTAGCTAGCTA",
     "# \"\"\"",
     "# seq_manager.load_fasta_string(fasta_string)",
     "",
     "# Example 3: Fetch from NCBI (uncomment and modify)",
     "# seq_manager.fetch_ncbi_sequence(\"NC_000001.11\", \"your_email@example.com\")  # Human chromosome 1 (partial)",
     "",
     "print(\"\ud83d\udca1 To add your own sequences:\")",
     "print(\"   1. Uncomment and modify the examples above\")",
     "print(\"   2. Use seq_manager.add_sequence(sequence, name) for direct input\")",
     "print(\"   3. Use seq_manager.load_fasta_string(fasta_content) for FASTA format\")",
     "print(\"   4. Use seq_manager.fetch_ncbi_sequence(accession, email) for NCBI sequences\")",
     "",
     "# Display current sequence count",
     "print(f\"\\n\ud83d\udcca Currently loaded sequences: {len(seq_manager.sequences)}\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 4. Complete Motif Detection Pipeline",
     "",
     "### \ud83e\uddec Comprehensive Non-B DNA Analysis",
     "",
     "This section performs complete motif detection across all 10 categories of non-B DNA structures."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class NBDFinderAnalyzer:",
     "    \"\"\"Complete NBDFinder analysis pipeline\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.results = {}",
     "        self.analysis_metadata = {}",
     "        ",
     "        # Initialize advanced modules if available",
     "        try:",
     "            self.disease_detector = AdvancedDiseaseDetector()",
     "            self.ml_predictor = AdvancedMLPredictor()",
     "            self.viz_engine = PublicationVisualizer()",
     "            print(\"\u2705 Advanced analysis modules initialized\")",
     "        except:",
     "            print(\"\u26a0\ufe0f Some advanced modules not available - basic analysis will still work\")",
     "    ",
     "    def analyze_sequence(self, sequence: str, sequence_name: str, ",
     "                        include_ml: bool = True, ",
     "                        include_disease: bool = True,",
     "                        include_conservation: bool = True) -> Dict:",
     "        \"\"\"Perform comprehensive analysis on a single sequence\"\"\"",
     "        ",
     "        print(f\"\\n\ud83d\udd2c Analyzing sequence: {sequence_name}\")",
     "        print(f\"   Length: {len(sequence):,} bp\")",
     "        print(f\"   GC Content: {gc_content(sequence):.1f}%\")",
     "        ",
     "        start_time = time.time()",
     "        ",
     "        # Core motif detection",
     "        motifs = all_motifs(",
     "            sequence, ",
     "            nonoverlap=False, ",
     "            report_hotspots=True,",
     "            sequence_name=sequence_name",
     "        )",
     "        ",
     "        # Enhance with machine learning if available",
     "        if include_ml and hasattr(self, 'ml_predictor'):",
     "            enhanced_motifs = []",
     "            for motif in motifs:",
     "                try:",
     "                    enhanced_motif = enhance_motif_with_ml(motif, sequence)",
     "                    enhanced_motifs.append(enhanced_motif)",
     "                except:",
     "                    enhanced_motifs.append(motif)",
     "            motifs = enhanced_motifs",
     "        ",
     "        # Disease/clinical analysis",
     "        disease_motifs = []",
     "        if include_disease and hasattr(self, 'disease_detector'):",
     "            try:",
     "                disease_motifs = self.disease_detector.detect_pathogenic_repeats(sequence)",
     "                print(f\"   \ud83c\udfe5 Found {len(disease_motifs)} disease-associated motifs\")",
     "            except Exception as e:",
     "                print(f\"   \u26a0\ufe0f Disease analysis failed: {e}\")",
     "        ",
     "        # Analysis timing",
     "        analysis_time = time.time() - start_time",
     "        ",
     "        # Compile results",
     "        result = {",
     "            'sequence_name': sequence_name,",
     "            'sequence_length': len(sequence),",
     "            'gc_content': gc_content(sequence),",
     "            'analysis_time': analysis_time,",
     "            'motifs': motifs,",
     "            'disease_motifs': disease_motifs,",
     "            'total_motifs': len(motifs),",
     "            'motif_density': len(motifs) / len(sequence) * 1000,  # motifs per kb",
     "            'timestamp': datetime.now().isoformat()",
     "        }",
     "        ",
     "        # Motif class distribution",
     "        class_counts = Counter(motif.get('Class', 'Unknown') for motif in motifs)",
     "        result['motif_classes'] = dict(class_counts)",
     "        ",
     "        # Store results",
     "        self.results[sequence_name] = result",
     "        ",
     "        print(f\"   \u2705 Analysis complete: {len(motifs)} motifs found in {analysis_time:.2f}s\")",
     "        print(f\"   \ud83d\udcca Motif density: {result['motif_density']:.1f} motifs/kb\")",
     "        ",
     "        return result",
     "    ",
     "    def analyze_all_sequences(self, seq_manager: NBDFinderSequenceManager, **kwargs) -> Dict:",
     "        \"\"\"Analyze all sequences in the sequence manager\"\"\"",
     "        ",
     "        if not seq_manager.sequences:",
     "            print(\"\u274c No sequences to analyze\")",
     "            return {}",
     "        ",
     "        print(f\"\ud83d\ude80 Starting analysis of {len(seq_manager.sequences)} sequences...\")",
     "        ",
     "        all_results = {}",
     "        ",
     "        for i, (sequence, name) in enumerate(zip(seq_manager.sequences, seq_manager.sequence_names)):",
     "            print(f\"\\n[{i+1}/{len(seq_manager.sequences)}]\")",
     "            result = self.analyze_sequence(sequence, name, **kwargs)",
     "            all_results[name] = result",
     "        ",
     "        # Generate summary statistics",
     "        self.generate_analysis_summary(all_results)",
     "        ",
     "        return all_results",
     "    ",
     "    def generate_analysis_summary(self, results: Dict) -> Dict:",
     "        \"\"\"Generate comprehensive analysis summary\"\"\"",
     "        ",
     "        if not results:",
     "            return {}",
     "        ",
     "        # Aggregate statistics",
     "        total_sequences = len(results)",
     "        total_motifs = sum(r['total_motifs'] for r in results.values())",
     "        total_nucleotides = sum(r['sequence_length'] for r in results.values())",
     "        avg_gc = np.mean([r['gc_content'] for r in results.values()])",
     "        avg_density = np.mean([r['motif_density'] for r in results.values()])",
     "        ",
     "        # Class distribution across all sequences",
     "        all_classes = Counter()",
     "        for result in results.values():",
     "            all_classes.update(result['motif_classes'])",
     "        ",
     "        summary = {",
     "            'total_sequences': total_sequences,",
     "            'total_motifs': total_motifs,",
     "            'total_nucleotides': total_nucleotides,",
     "            'average_gc_content': avg_gc,",
     "            'average_motif_density': avg_density,",
     "            'motif_class_distribution': dict(all_classes),",
     "            'analysis_timestamp': datetime.now().isoformat()",
     "        }",
     "        ",
     "        self.analysis_metadata['summary'] = summary",
     "        ",
     "        print(f\"\\n\ud83d\udcca Analysis Summary:\")",
     "        print(f\"   \u2022 Total sequences analyzed: {total_sequences}\")",
     "        print(f\"   \u2022 Total motifs found: {total_motifs:,}\")",
     "        print(f\"   \u2022 Total nucleotides: {total_nucleotides:,}\")",
     "        print(f\"   \u2022 Average GC content: {avg_gc:.1f}%\")",
     "        print(f\"   \u2022 Average motif density: {avg_density:.1f} motifs/kb\")",
     "        print(f\"   \u2022 Top motif classes: {dict(list(all_classes.most_common(5)))}\")",
     "        ",
     "        return summary",
     "    ",
     "    def get_results_dataframe(self) -> pd.DataFrame:",
     "        \"\"\"Convert results to a comprehensive DataFrame\"\"\"",
     "        ",
     "        if not self.results:",
     "            return pd.DataFrame()",
     "        ",
     "        # Flatten all motifs into a single DataFrame",
     "        all_motifs_data = []",
     "        ",
     "        for seq_name, result in self.results.items():",
     "            for motif in result['motifs']:",
     "                motif_data = motif.copy()",
     "                motif_data['Analysis_Sequence'] = seq_name",
     "                motif_data['Sequence_Length'] = result['sequence_length']",
     "                motif_data['Sequence_GC'] = result['gc_content']",
     "                all_motifs_data.append(motif_data)",
     "        ",
     "        if not all_motifs_data:",
     "            return pd.DataFrame()",
     "        ",
     "        df = pd.DataFrame(all_motifs_data)",
     "        ",
     "        # Ensure consistent column order",
     "        priority_columns = [",
     "            'Analysis_Sequence', 'Sequence Name', 'Class', 'Subtype', ",
     "            'Start', 'End', 'Length', 'Sequence', 'Score', ",
     "            'Sequence_Length', 'Sequence_GC'",
     "        ]",
     "        ",
     "        # Reorder columns",
     "        existing_priority = [col for col in priority_columns if col in df.columns]",
     "        other_columns = [col for col in df.columns if col not in priority_columns]",
     "        df = df[existing_priority + other_columns]",
     "        ",
     "        return df",
     "",
     "# Initialize analyzer",
     "analyzer = NBDFinderAnalyzer()",
     "print(\"\u2705 NBDFinder analyzer initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### \ud83d\ude80 Run Complete Analysis",
     "",
     "Execute comprehensive motif detection on all loaded sequences."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Run comprehensive analysis",
     "if seq_manager.sequences:",
     "    print(\"\ud83d\ude80 Starting comprehensive NBDFinder analysis...\")",
     "    print(\"This may take a few minutes depending on sequence length and number.\")",
     "    ",
     "    # Configure analysis options",
     "    analysis_options = {",
     "        'include_ml': True,  # Include machine learning predictions",
     "        'include_disease': True,  # Include disease motif analysis",
     "        'include_conservation': True  # Include conservation analysis",
     "    }",
     "    ",
     "    # Run analysis",
     "    results = analyzer.analyze_all_sequences(seq_manager, **analysis_options)",
     "    ",
     "    print(\"\\n\ud83c\udf89 Analysis complete!\")",
     "    ",
     "    # Convert to DataFrame for easy viewing",
     "    results_df = analyzer.get_results_dataframe()",
     "    ",
     "    if not results_df.empty:",
     "        print(f\"\\n\ud83d\udcca Results Overview:\")",
     "        print(f\"   \u2022 Total motifs detected: {len(results_df):,}\")",
     "        print(f\"   \u2022 Unique motif classes: {results_df['Class'].nunique()}\")",
     "        print(f\"   \u2022 Unique motif subtypes: {results_df['Subtype'].nunique()}\")",
     "        ",
     "        # Show first few results",
     "        print(f\"\\n\ud83d\udd0d First 10 detected motifs:\")",
     "        display(results_df[['Analysis_Sequence', 'Class', 'Subtype', 'Start', 'End', 'Length', 'Score']].head(10))",
     "        ",
     "        # Class distribution",
     "        print(f\"\\n\ud83d\udcc8 Motif class distribution:\")",
     "        class_counts = results_df['Class'].value_counts()",
     "        display(class_counts.head(10))",
     "        ",
     "    else:",
     "        print(\"\u26a0\ufe0f No motifs detected in the analyzed sequences\")",
     "        ",
     "else:",
     "    print(\"\u274c No sequences loaded. Please load sequences first.\")",
     "    print(\"\ud83d\udca1 Use the sequence loading sections above to add sequences for analysis.\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 5. Advanced Visualization Suite",
     "",
     "### \ud83d\udcca Publication-Quality Visualizations",
     "",
     "Comprehensive visualization capabilities for motif analysis results."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class ComprehensiveVisualizationSuite:",
     "    \"\"\"Advanced visualization suite for NBDFinder results\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.color_palette = px.colors.qualitative.Set3",
     "        ",
     "    def plot_motif_distribution(self, results_df: pd.DataFrame) -> None:",
     "        \"\"\"Create comprehensive motif distribution plots\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No data to visualize\")",
     "            return",
     "        ",
     "        # Class distribution pie chart",
     "        fig1 = px.pie(",
     "            values=results_df['Class'].value_counts().values,",
     "            names=results_df['Class'].value_counts().index,",
     "            title=\"Motif Class Distribution\",",
     "            color_discrete_sequence=self.color_palette",
     "        )",
     "        fig1.show()",
     "        ",
     "        # Motif length distribution",
     "        fig2 = px.histogram(",
     "            results_df, ",
     "            x='Length', ",
     "            color='Class',",
     "            title=\"Motif Length Distribution by Class\",",
     "            nbins=30",
     "        )",
     "        fig2.update_layout(xaxis_title=\"Motif Length (bp)\", yaxis_title=\"Count\")",
     "        fig2.show()",
     "        ",
     "        # Score distribution by class",
     "        if 'Score' in results_df.columns:",
     "            fig3 = px.box(",
     "                results_df,",
     "                x='Class',",
     "                y='Score',",
     "                title=\"Score Distribution by Motif Class\"",
     "            )",
     "            fig3.update_xaxis(tickangle=45)",
     "            fig3.show()",
     "    ",
     "    def plot_sequence_overview(self, results_df: pd.DataFrame, seq_manager) -> None:",
     "        \"\"\"Create sequence-level overview plots\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No data to visualize\")",
     "            return",
     "        ",
     "        # Motif density per sequence",
     "        seq_summary = results_df.groupby('Analysis_Sequence').agg({",
     "            'Class': 'count',",
     "            'Sequence_Length': 'first',",
     "            'Sequence_GC': 'first'",
     "        }).rename(columns={'Class': 'Motif_Count'})",
     "        ",
     "        seq_summary['Motif_Density'] = seq_summary['Motif_Count'] / seq_summary['Sequence_Length'] * 1000",
     "        ",
     "        # Density vs GC content",
     "        fig1 = px.scatter(",
     "            seq_summary,",
     "            x='Sequence_GC',",
     "            y='Motif_Density',",
     "            size='Sequence_Length',",
     "            hover_name=seq_summary.index,",
     "            title=\"Motif Density vs GC Content\",",
     "            labels={'Sequence_GC': 'GC Content (%)', 'Motif_Density': 'Motifs per kb'}",
     "        )",
     "        fig1.show()",
     "        ",
     "        # Motif counts per sequence",
     "        fig2 = px.bar(",
     "            x=seq_summary.index,",
     "            y=seq_summary['Motif_Count'],",
     "            title=\"Total Motifs per Sequence\",",
     "            labels={'x': 'Sequence', 'y': 'Motif Count'}",
     "        )",
     "        fig2.update_xaxis(tickangle=45)",
     "        fig2.show()",
     "    ",
     "    def plot_motif_locations(self, results_df: pd.DataFrame, sequence_name: str = None) -> None:",
     "        \"\"\"Plot motif locations along sequences\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No data to visualize\")",
     "            return",
     "        ",
     "        # Filter to specific sequence if provided",
     "        if sequence_name:",
     "            plot_data = results_df[results_df['Analysis_Sequence'] == sequence_name]",
     "            if plot_data.empty:",
     "                print(f\"\u274c No data found for sequence: {sequence_name}\")",
     "                return",
     "        else:",
     "            plot_data = results_df",
     "        ",
     "        # Create motif location plot",
     "        fig = go.Figure()",
     "        ",
     "        for i, (seq_name, group) in enumerate(plot_data.groupby('Analysis_Sequence')):",
     "            y_offset = i * 2",
     "            ",
     "            # Add sequence line",
     "            seq_length = group['Sequence_Length'].iloc[0]",
     "            fig.add_trace(go.Scatter(",
     "                x=[0, seq_length],",
     "                y=[y_offset, y_offset],",
     "                mode='lines',",
     "                line=dict(color='lightgray', width=3),",
     "                name=f\"{seq_name} (baseline)\",",
     "                showlegend=False",
     "            ))",
     "            ",
     "            # Add motifs",
     "            for _, motif in group.iterrows():",
     "                fig.add_trace(go.Scatter(",
     "                    x=[motif['Start'], motif['End']],",
     "                    y=[y_offset + 0.2, y_offset + 0.2],",
     "                    mode='lines+markers',",
     "                    line=dict(width=8),",
     "                    name=motif['Class'],",
     "                    text=f\"{motif['Class']}: {motif['Start']}-{motif['End']}\",",
     "                    hovertemplate='%{text}<extra></extra>'",
     "                ))",
     "        ",
     "        fig.update_layout(",
     "            title=\"Motif Locations Along Sequences\",",
     "            xaxis_title=\"Position (bp)\",",
     "            yaxis_title=\"Sequence\",",
     "            height=max(400, len(plot_data['Analysis_Sequence'].unique()) * 100)",
     "        )",
     "        fig.show()",
     "    ",
     "    def create_comparative_heatmap(self, results_df: pd.DataFrame) -> None:",
     "        \"\"\"Create heatmap comparing motif classes across sequences\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No data to visualize\")",
     "            return",
     "        ",
     "        # Create pivot table",
     "        heatmap_data = results_df.groupby(['Analysis_Sequence', 'Class']).size().unstack(fill_value=0)",
     "        ",
     "        # Create heatmap",
     "        fig = px.imshow(",
     "            heatmap_data.values,",
     "            x=heatmap_data.columns,",
     "            y=heatmap_data.index,",
     "            color_continuous_scale='Viridis',",
     "            title=\"Motif Class Distribution Heatmap\"",
     "        )",
     "        fig.update_layout(",
     "            xaxis_title=\"Motif Class\",",
     "            yaxis_title=\"Sequence\"",
     "        )",
     "        fig.show()",
     "",
     "# Initialize visualization suite",
     "viz_suite = ComprehensiveVisualizationSuite()",
     "print(\"\u2705 Visualization suite initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### \ud83c\udfa8 Generate Comprehensive Visualizations",
     "",
     "Create publication-quality plots and interactive visualizations of the analysis results."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Generate comprehensive visualizations",
     "if 'results_df' in locals() and not results_df.empty:",
     "    print(\"\ud83c\udfa8 Generating comprehensive visualizations...\")",
     "    ",
     "    # 1. Motif distribution plots",
     "    print(\"\\n\ud83d\udcca Creating motif distribution plots...\")",
     "    viz_suite.plot_motif_distribution(results_df)",
     "    ",
     "    # 2. Sequence overview plots",
     "    print(\"\\n\ud83d\udd0d Creating sequence overview plots...\")",
     "    viz_suite.plot_sequence_overview(results_df, seq_manager)",
     "    ",
     "    # 3. Motif location plots",
     "    print(\"\\n\ud83d\udccd Creating motif location plots...\")",
     "    viz_suite.plot_motif_locations(results_df)",
     "    ",
     "    # 4. Comparative heatmap",
     "    print(\"\\n\ud83d\udd25 Creating comparative heatmap...\")",
     "    viz_suite.create_comparative_heatmap(results_df)",
     "    ",
     "    print(\"\\n\u2705 All visualizations generated!\")",
     "    ",
     "else:",
     "    print(\"\u274c No analysis results available for visualization.\")",
     "    print(\"\ud83d\udca1 Run the analysis section first to generate data for visualization.\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 6. Clinical and Disease Analysis",
     "",
     "### \ud83c\udfe5 Pathogenic Repeat Detection and Clinical Interpretation",
     "",
     "This section provides clinical-grade analysis for disease-associated motifs with ACMG guidelines."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class ClinicalAnalysisModule:",
     "    \"\"\"Clinical analysis module for disease-associated motifs\"\"\"",
     "    ",
     "    def __init__(self):",
     "        # Disease-associated repeat thresholds",
     "        self.disease_thresholds = {",
     "            'Friedreich_Ataxia': {'repeat': 'GAA', 'normal': '<20', 'pathogenic': '>59'},",
     "            'Fragile_X': {'repeat': 'CGG', 'normal': '<45', 'pathogenic': '>200'},",
     "            'Huntington': {'repeat': 'CAG', 'normal': '<27', 'pathogenic': '>36'},",
     "            'Myotonic_Dystrophy': {'repeat': 'CTG', 'normal': '<19', 'pathogenic': '>50'},",
     "            'Spinocerebellar_Ataxia': {'repeat': 'CAG', 'normal': '<30', 'pathogenic': '>40'}",
     "        }",
     "    ",
     "    def analyze_clinical_significance(self, results_df: pd.DataFrame) -> pd.DataFrame:",
     "        \"\"\"Analyze clinical significance of detected motifs\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No data for clinical analysis\")",
     "            return pd.DataFrame()",
     "        ",
     "        clinical_results = []",
     "        ",
     "        for _, motif in results_df.iterrows():",
     "            sequence = motif.get('Sequence', '')",
     "            motif_class = motif.get('Class', '')",
     "            length = motif.get('Length', 0)",
     "            ",
     "            # Check for disease-associated patterns",
     "            clinical_sig = self._assess_clinical_significance(sequence, motif_class, length)",
     "            ",
     "            clinical_data = {",
     "                'Motif_ID': f\"{motif['Analysis_Sequence']}_{motif['Start']}_{motif['End']}\",",
     "                'Sequence_Name': motif['Analysis_Sequence'],",
     "                'Motif_Class': motif_class,",
     "                'Start': motif.get('Start', 0),",
     "                'End': motif.get('End', 0),",
     "                'Length': length,",
     "                'Sequence': sequence,",
     "                'Clinical_Significance': clinical_sig['significance'],",
     "                'Disease_Association': clinical_sig['disease'],",
     "                'Risk_Level': clinical_sig['risk_level'],",
     "                'Recommendation': clinical_sig['recommendation'],",
     "                'Literature_Support': clinical_sig['literature']",
     "            }",
     "            clinical_results.append(clinical_data)",
     "        ",
     "        clinical_df = pd.DataFrame(clinical_results)",
     "        ",
     "        # Filter for clinically significant findings",
     "        significant_findings = clinical_df[",
     "            clinical_df['Clinical_Significance'].isin(['Pathogenic', 'Likely Pathogenic', 'VUS'])",
     "        ]",
     "        ",
     "        if not significant_findings.empty:",
     "            print(f\"\\n\ud83c\udfe5 Clinical Analysis Results:\")",
     "            print(f\"   \u2022 Total motifs analyzed: {len(clinical_df)}\")",
     "            print(f\"   \u2022 Clinically significant findings: {len(significant_findings)}\")",
     "            print(f\"   \u2022 Pathogenic/Likely Pathogenic: {len(significant_findings[significant_findings['Clinical_Significance'].isin(['Pathogenic', 'Likely Pathogenic'])])}\")",
     "            ",
     "            display(significant_findings[['Sequence_Name', 'Motif_Class', 'Clinical_Significance', 'Disease_Association', 'Risk_Level']].head(10))",
     "        ",
     "        return clinical_df",
     "    ",
     "    def _assess_clinical_significance(self, sequence: str, motif_class: str, length: int) -> Dict:",
     "        \"\"\"Assess clinical significance of a motif\"\"\"",
     "        ",
     "        # Default values",
     "        result = {",
     "            'significance': 'Benign',",
     "            'disease': 'None identified',",
     "            'risk_level': 'Low',",
     "            'recommendation': 'No action required',",
     "            'literature': 'No specific literature'",
     "        }",
     "        ",
     "        # Check for specific disease patterns",
     "        if 'GAA' in sequence and length > 100:",
     "            repeat_count = len(sequence) // 3",
     "            if repeat_count > 59:",
     "                result.update({",
     "                    'significance': 'Pathogenic',",
     "                    'disease': 'Friedreich Ataxia',",
     "                    'risk_level': 'Very High',",
     "                    'recommendation': 'Genetic counseling recommended',",
     "                    'literature': 'PMID: 10196364, 11343488'",
     "                })",
     "            elif repeat_count > 35:",
     "                result.update({",
     "                    'significance': 'VUS',",
     "                    'disease': 'Possible Friedreich Ataxia',",
     "                    'risk_level': 'Moderate',",
     "                    'recommendation': 'Additional testing recommended'",
     "                })",
     "        ",
     "        elif 'CGG' in sequence and length > 100:",
     "            repeat_count = len(sequence) // 3",
     "            if repeat_count > 200:",
     "                result.update({",
     "                    'significance': 'Pathogenic',",
     "                    'disease': 'Fragile X Syndrome',",
     "                    'risk_level': 'Very High',",
     "                    'recommendation': 'Genetic counseling required',",
     "                    'literature': 'PMID: 1944298, 1935689'",
     "                })",
     "            elif repeat_count > 55:",
     "                result.update({",
     "                    'significance': 'Likely Pathogenic',",
     "                    'disease': 'Fragile X Premutation',",
     "                    'risk_level': 'High',",
     "                    'recommendation': 'Family screening recommended'",
     "                })",
     "        ",
     "        elif 'CAG' in sequence and motif_class in ['Slipped DNA', 'Sticky DNA']:",
     "            repeat_count = len(sequence) // 3",
     "            if repeat_count > 36:",
     "                result.update({",
     "                    'significance': 'Pathogenic',",
     "                    'disease': 'Huntington Disease',",
     "                    'risk_level': 'Very High',",
     "                    'recommendation': 'Immediate genetic counseling',",
     "                    'literature': 'PMID: 8458085, 1677316'",
     "                })",
     "        ",
     "        return result",
     "    ",
     "    def generate_clinical_report(self, clinical_df: pd.DataFrame, output_file: str = None) -> str:",
     "        \"\"\"Generate comprehensive clinical report\"\"\"",
     "        ",
     "        if clinical_df.empty:",
     "            return \"No clinical data available for report generation.\"",
     "        ",
     "        # Generate report content",
     "        report_content = f\"\"\"",
     "# NBDFinder Clinical Analysis Report",
     "",
     "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
     "**Platform:** NBDFinder v2.0.0",
     "",
     "## Summary Statistics",
     "",
     "- **Total Motifs Analyzed:** {len(clinical_df)}",
     "- **Pathogenic Findings:** {len(clinical_df[clinical_df['Clinical_Significance'] == 'Pathogenic'])}",
     "- **Likely Pathogenic:** {len(clinical_df[clinical_df['Clinical_Significance'] == 'Likely Pathogenic'])}",
     "- **Variants of Uncertain Significance (VUS):** {len(clinical_df[clinical_df['Clinical_Significance'] == 'VUS'])}",
     "- **Benign Findings:** {len(clinical_df[clinical_df['Clinical_Significance'] == 'Benign'])}",
     "",
     "## Clinically Significant Findings",
     "",
     "\"\"\"",
     "        ",
     "        # Add significant findings",
     "        significant = clinical_df[clinical_df['Clinical_Significance'].isin(['Pathogenic', 'Likely Pathogenic', 'VUS'])]",
     "        ",
     "        for _, finding in significant.iterrows():",
     "            report_content += f\"\"\"",
     "### Finding {finding['Motif_ID']}",
     "",
     "- **Classification:** {finding['Clinical_Significance']}",
     "- **Disease Association:** {finding['Disease_Association']}",
     "- **Risk Level:** {finding['Risk_Level']}",
     "- **Location:** {finding['Start']}-{finding['End']} bp",
     "- **Motif Class:** {finding['Motif_Class']}",
     "- **Recommendation:** {finding['Recommendation']}",
     "- **Literature:** {finding['Literature_Support']}",
     "",
     "\"\"\"",
     "        ",
     "        report_content += \"\"\"",
     "## Recommendations",
     "",
     "1. **Pathogenic findings** require immediate genetic counseling and family screening",
     "2. **Likely pathogenic findings** warrant genetic counseling consultation",
     "3. **VUS findings** should be monitored and may require additional testing",
     "4. **All findings** should be confirmed with orthogonal clinical testing methods",
     "",
     "## Disclaimer",
     "",
     "This analysis is for research purposes only and should not be used for clinical decision-making without proper validation and clinical oversight.",
     "\"\"\"",
     "        ",
     "        # Save report if filename provided",
     "        if output_file:",
     "            with open(output_file, 'w') as f:",
     "                f.write(report_content)",
     "            print(f\"\ud83d\udcc4 Clinical report saved to: {output_file}\")",
     "        ",
     "        return report_content",
     "",
     "# Initialize clinical analysis module",
     "clinical_module = ClinicalAnalysisModule()",
     "print(\"\u2705 Clinical analysis module initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### \ud83e\ude7a Execute Clinical Analysis",
     "",
     "Perform comprehensive clinical analysis on detected motifs."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Run clinical analysis",
     "if 'results_df' in locals() and not results_df.empty:",
     "    print(\"\ud83e\ude7a Running clinical analysis...\")",
     "    ",
     "    # Analyze clinical significance",
     "    clinical_results = clinical_module.analyze_clinical_significance(results_df)",
     "    ",
     "    # Generate clinical report",
     "    clinical_report = clinical_module.generate_clinical_report(clinical_results, \"clinical_analysis_report.md\")",
     "    ",
     "    # Display key clinical findings",
     "    significant_clinical = clinical_results[",
     "        clinical_results['Clinical_Significance'].isin(['Pathogenic', 'Likely Pathogenic', 'VUS'])",
     "    ]",
     "    ",
     "    if not significant_clinical.empty:",
     "        print(\"\\n\ud83d\udea8 Clinically Significant Findings:\")",
     "        display(significant_clinical[['Sequence_Name', 'Motif_Class', 'Clinical_Significance', 'Disease_Association', 'Risk_Level']])",
     "    else:",
     "        print(\"\\n\u2705 No clinically significant findings detected\")",
     "    ",
     "else:",
     "    print(\"\u274c No analysis results available for clinical analysis.\")",
     "    print(\"\ud83d\udca1 Run the motif detection analysis first.\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 7. Bacterial Genome Comparative Analysis",
     "",
     "### \ud83e\udda0 Comparative Genomics and Bacterial Analysis",
     "",
     "Comprehensive bacterial genome analysis with comparative capabilities."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class BacterialGenomeComparativeAnalysis:",
     "    \"\"\"Bacterial genome comparative analysis module\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.genome_categories = {",
     "            'High GC': {'min_gc': 60, 'max_gc': 100, 'examples': ['Mycobacterium', 'Streptomyces']},",
     "            'Medium GC': {'min_gc': 40, 'max_gc': 60, 'examples': ['E. coli', 'Bacillus']},",
     "            'Low GC': {'min_gc': 20, 'max_gc': 40, 'examples': ['Clostridium', 'Mycoplasma']}",
     "        }",
     "    ",
     "    def analyze_bacterial_sequence(self, sequence: str, organism_name: str) -> Dict:",
     "        \"\"\"Analyze a bacterial genome sequence\"\"\"",
     "        ",
     "        print(f\"\ud83e\udda0 Analyzing bacterial genome: {organism_name}\")",
     "        ",
     "        # Basic statistics",
     "        gc_content_val = gc_content(sequence)",
     "        length = len(sequence)",
     "        ",
     "        # Categorize by GC content",
     "        gc_category = self._categorize_by_gc(gc_content_val)",
     "        ",
     "        # Run motif analysis",
     "        motifs = all_motifs(sequence, nonoverlap=False, sequence_name=organism_name)",
     "        ",
     "        # Analyze motif patterns specific to bacteria",
     "        bacterial_patterns = self._analyze_bacterial_patterns(motifs, sequence)",
     "        ",
     "        # Calculate genome statistics",
     "        stats = {",
     "            'organism': organism_name,",
     "            'length': length,",
     "            'gc_content': gc_content_val,",
     "            'gc_category': gc_category,",
     "            'total_motifs': len(motifs),",
     "            'motif_density': len(motifs) / length * 1000,",
     "            'bacterial_patterns': bacterial_patterns,",
     "            'motifs': motifs",
     "        }",
     "        ",
     "        # Motif class distribution",
     "        class_counts = Counter(motif.get('Class', 'Unknown') for motif in motifs)",
     "        stats['motif_classes'] = dict(class_counts)",
     "        ",
     "        print(f\"   \ud83d\udcca {len(motifs)} motifs found (GC: {gc_content_val:.1f}%, Category: {gc_category})\")",
     "        ",
     "        return stats",
     "    ",
     "    def _categorize_by_gc(self, gc_val: float) -> str:",
     "        \"\"\"Categorize genome by GC content\"\"\"",
     "        for category, info in self.genome_categories.items():",
     "            if info['min_gc'] <= gc_val < info['max_gc']:",
     "                return category",
     "        return 'Unknown'",
     "    ",
     "    def _analyze_bacterial_patterns(self, motifs: List[Dict], sequence: str) -> Dict:",
     "        \"\"\"Analyze bacterial-specific patterns\"\"\"",
     "        ",
     "        patterns = {",
     "            'replication_origins': 0,",
     "            'transcription_factors': 0,",
     "            'restriction_sites': 0,",
     "            'stress_response': 0,",
     "            'pathogenicity': 0",
     "        }",
     "        ",
     "        # Count specific bacterial patterns",
     "        for motif in motifs:",
     "            motif_seq = motif.get('Sequence', '').upper()",
     "            motif_class = motif.get('Class', '')",
     "            ",
     "            # Replication origin indicators",
     "            if motif_class in ['Z-DNA', 'Curved DNA'] or 'GATC' in motif_seq:",
     "                patterns['replication_origins'] += 1",
     "            ",
     "            # Transcription factor binding sites",
     "            if motif_class in ['Cruciform', 'Hairpin'] or any(x in motif_seq for x in ['TATA', 'CAAT']):",
     "                patterns['transcription_factors'] += 1",
     "            ",
     "            # Restriction enzyme sites",
     "            if motif_class == 'Hairpin' and len(motif_seq) < 20:",
     "                patterns['restriction_sites'] += 1",
     "            ",
     "            # Stress response elements",
     "            if motif_class in ['G-Quadruplex', 'R-loop']:",
     "                patterns['stress_response'] += 1",
     "            ",
     "            # Potential pathogenicity factors",
     "            if motif_class in ['Slipped DNA', 'Sticky DNA'] and len(motif_seq) > 50:",
     "                patterns['pathogenicity'] += 1",
     "        ",
     "        return patterns",
     "    ",
     "    def compare_bacterial_genomes(self, genome_results: List[Dict]) -> Dict:",
     "        \"\"\"Compare multiple bacterial genomes\"\"\"",
     "        ",
     "        if not genome_results:",
     "            return {}",
     "        ",
     "        print(f\"\ud83d\udd2c Comparing {len(genome_results)} bacterial genomes...\")",
     "        ",
     "        # Create comparison DataFrame",
     "        comparison_data = []",
     "        for result in genome_results:",
     "            comparison_data.append({",
     "                'Organism': result['organism'],",
     "                'Length (Mbp)': result['length'] / 1e6,",
     "                'GC Content (%)': result['gc_content'],",
     "                'GC Category': result['gc_category'],",
     "                'Total Motifs': result['total_motifs'],",
     "                'Motif Density': result['motif_density'],",
     "                'Replication Origins': result['bacterial_patterns']['replication_origins'],",
     "                'Transcription Factors': result['bacterial_patterns']['transcription_factors'],",
     "                'Stress Response': result['bacterial_patterns']['stress_response']",
     "            })",
     "        ",
     "        comparison_df = pd.DataFrame(comparison_data)",
     "        ",
     "        # Statistical analysis",
     "        stats_summary = {",
     "            'comparison_data': comparison_df,",
     "            'gc_content_stats': {",
     "                'mean': comparison_df['GC Content (%)'].mean(),",
     "                'std': comparison_df['GC Content (%)'].std(),",
     "                'range': [comparison_df['GC Content (%)'].min(), comparison_df['GC Content (%)'].max()]",
     "            },",
     "            'motif_density_stats': {",
     "                'mean': comparison_df['Motif Density'].mean(),",
     "                'std': comparison_df['Motif Density'].std(),",
     "                'correlation_with_gc': comparison_df['GC Content (%)'].corr(comparison_df['Motif Density'])",
     "            }",
     "        }",
     "        ",
     "        print(\"\\n\ud83d\udcca Comparative Analysis Summary:\")",
     "        print(f\"   \u2022 Average GC content: {stats_summary['gc_content_stats']['mean']:.1f}%\")",
     "        print(f\"   \u2022 GC content range: {stats_summary['gc_content_stats']['range'][0]:.1f}% - {stats_summary['gc_content_stats']['range'][1]:.1f}%\")",
     "        print(f\"   \u2022 Average motif density: {stats_summary['motif_density_stats']['mean']:.1f} motifs/kb\")",
     "        print(f\"   \u2022 GC-Motif correlation: {stats_summary['motif_density_stats']['correlation_with_gc']:.3f}\")",
     "        ",
     "        return stats_summary",
     "    ",
     "    def visualize_bacterial_comparison(self, comparison_results: Dict) -> None:",
     "        \"\"\"Create visualizations for bacterial genome comparison\"\"\"",
     "        ",
     "        if not comparison_results or 'comparison_data' not in comparison_results:",
     "            print(\"\u274c No comparison data for visualization\")",
     "            return",
     "        ",
     "        df = comparison_results['comparison_data']",
     "        ",
     "        # GC content vs Motif density scatter plot",
     "        fig1 = px.scatter(",
     "            df,",
     "            x='GC Content (%)',",
     "            y='Motif Density',",
     "            size='Length (Mbp)',",
     "            color='GC Category',",
     "            hover_name='Organism',",
     "            title=\"Bacterial Genome: GC Content vs Motif Density\"",
     "        )",
     "        fig1.show()",
     "        ",
     "        # Motif class comparison heatmap",
     "        fig2 = px.bar(",
     "            df,",
     "            x='Organism',",
     "            y=['Replication Origins', 'Transcription Factors', 'Stress Response'],",
     "            title=\"Bacterial-Specific Motif Patterns Comparison\"",
     "        )",
     "        fig2.update_xaxis(tickangle=45)",
     "        fig2.show()",
     "",
     "# Initialize bacterial analysis module",
     "bacterial_analyzer = BacterialGenomeComparativeAnalysis()",
     "print(\"\u2705 Bacterial genome analysis module initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 8. Machine Learning Integration",
     "",
     "### \ud83e\udd16 AI-Enhanced Motif Prediction and Analysis",
     "",
     "Advanced machine learning capabilities for motif prediction and validation."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class MLMotifAnalysis:",
     "    \"\"\"Machine learning integration for motif analysis\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.feature_scaler = StandardScaler()",
     "        self.is_trained = False",
     "        ",
     "    def extract_sequence_features(self, sequence: str) -> np.ndarray:",
     "        \"\"\"Extract numerical features from DNA sequence\"\"\"",
     "        ",
     "        features = []",
     "        ",
     "        # Basic composition features",
     "        length = len(sequence)",
     "        features.extend([",
     "            sequence.count('A') / length,",
     "            sequence.count('T') / length,",
     "            sequence.count('G') / length,",
     "            sequence.count('C') / length,",
     "            gc_content(sequence) / 100",
     "        ])",
     "        ",
     "        # Dinucleotide frequencies",
     "        dinucleotides = ['AA', 'AT', 'AG', 'AC', 'TA', 'TT', 'TG', 'TC',",
     "                        'GA', 'GT', 'GG', 'GC', 'CA', 'CT', 'CG', 'CC']",
     "        for dinuc in dinucleotides:",
     "            count = len(re.findall(dinuc, sequence))",
     "            features.append(count / (length - 1) if length > 1 else 0)",
     "        ",
     "        # Structural features",
     "        features.extend([",
     "            length,",
     "            self._calculate_purine_pyrimidine_ratio(sequence),",
     "            self._calculate_repeat_score(sequence),",
     "            self._calculate_palindrome_score(sequence)",
     "        ])",
     "        ",
     "        return np.array(features)",
     "    ",
     "    def _calculate_purine_pyrimidine_ratio(self, sequence: str) -> float:",
     "        \"\"\"Calculate purine to pyrimidine ratio\"\"\"",
     "        purines = sequence.count('A') + sequence.count('G')",
     "        pyrimidines = sequence.count('T') + sequence.count('C')",
     "        return purines / pyrimidines if pyrimidines > 0 else 0",
     "    ",
     "    def _calculate_repeat_score(self, sequence: str) -> float:",
     "        \"\"\"Calculate repetitive element score\"\"\"",
     "        max_repeat = 0",
     "        for i in range(1, min(10, len(sequence) // 2)):",
     "            for j in range(len(sequence) - i):",
     "                pattern = sequence[j:j+i]",
     "                count = 1",
     "                pos = j + i",
     "                while pos + i <= len(sequence) and sequence[pos:pos+i] == pattern:",
     "                    count += 1",
     "                    pos += i",
     "                max_repeat = max(max_repeat, count * i)",
     "        return max_repeat / len(sequence) if len(sequence) > 0 else 0",
     "    ",
     "    def _calculate_palindrome_score(self, sequence: str) -> float:",
     "        \"\"\"Calculate palindromic content score\"\"\"",
     "        palindrome_score = 0",
     "        for i in range(len(sequence)):",
     "            for j in range(i + 4, min(i + 20, len(sequence) + 1)):",
     "                subseq = sequence[i:j]",
     "                if subseq == reverse_complement(subseq):",
     "                    palindrome_score += len(subseq)",
     "        return palindrome_score / len(sequence) if len(sequence) > 0 else 0",
     "    ",
     "    def predict_motif_formation(self, motifs_df: pd.DataFrame) -> pd.DataFrame:",
     "        \"\"\"Predict motif formation probability using ML\"\"\"",
     "        ",
     "        if motifs_df.empty:",
     "            print(\"\u274c No motifs for ML prediction\")",
     "            return motifs_df",
     "        ",
     "        print(\"\ud83e\udd16 Generating ML predictions for motifs...\")",
     "        ",
     "        # Extract features for all motifs",
     "        features_list = []",
     "        for _, motif in motifs_df.iterrows():",
     "            sequence = motif.get('Sequence', '')",
     "            if len(sequence) >= 4:  # Minimum sequence length",
     "                features = self.extract_sequence_features(sequence)",
     "                features_list.append(features)",
     "            else:",
     "                # Use zeros for very short sequences",
     "                features_list.append(np.zeros(25))  # Adjust based on feature count",
     "        ",
     "        if not features_list:",
     "            print(\"\u274c No valid sequences for feature extraction\")",
     "            return motifs_df",
     "        ",
     "        features_array = np.array(features_list)",
     "        ",
     "        # Normalize features",
     "        if not self.is_trained:",
     "            features_normalized = self.feature_scaler.fit_transform(features_array)",
     "            self.is_trained = True",
     "        else:",
     "            features_normalized = self.feature_scaler.transform(features_array)",
     "        ",
     "        # Simple heuristic predictions (replace with trained model in production)",
     "        formation_probs = []",
     "        stability_scores = []",
     "        ",
     "        for i, (_, motif) in enumerate(motifs_df.iterrows()):",
     "            features = features_normalized[i]",
     "            motif_class = motif.get('Class', '')",
     "            ",
     "            # Heuristic probability based on features and class",
     "            base_prob = 0.5",
     "            ",
     "            # Adjust based on motif class",
     "            class_adjustments = {",
     "                'G-Quadruplex': 0.2,",
     "                'Z-DNA': 0.15,",
     "                'R-loop': 0.1,",
     "                'Cruciform': 0.1,",
     "                'Curved DNA': 0.05",
     "            }",
     "            base_prob += class_adjustments.get(motif_class, 0)",
     "            ",
     "            # Adjust based on sequence features",
     "            gc_content_feature = features[4] if len(features) > 4 else 0.5",
     "            if motif_class == 'G-Quadruplex' and gc_content_feature > 0.6:",
     "                base_prob += 0.1",
     "            elif motif_class == 'Z-DNA' and features[20] > 0.6:  # Purine-pyrimidine ratio",
     "                base_prob += 0.1",
     "            ",
     "            formation_probs.append(min(1.0, max(0.0, base_prob)))",
     "            stability_scores.append(min(1.0, max(0.0, base_prob * 0.8 + 0.2)))",
     "        ",
     "        # Add ML predictions to dataframe",
     "        motifs_df = motifs_df.copy()",
     "        motifs_df['ML_Formation_Probability'] = formation_probs",
     "        motifs_df['ML_Stability_Score'] = stability_scores",
     "        motifs_df['ML_Confidence'] = [0.7] * len(motifs_df)  # Fixed confidence for heuristic model",
     "        ",
     "        print(f\"\u2705 ML predictions generated for {len(motifs_df)} motifs\")",
     "        print(f\"   Average formation probability: {np.mean(formation_probs):.3f}\")",
     "        print(f\"   Average stability score: {np.mean(stability_scores):.3f}\")",
     "        ",
     "        return motifs_df",
     "    ",
     "    def create_ml_report(self, ml_enhanced_df: pd.DataFrame) -> str:",
     "        \"\"\"Create ML analysis report\"\"\"",
     "        ",
     "        if ml_enhanced_df.empty or 'ML_Formation_Probability' not in ml_enhanced_df.columns:",
     "            return \"No ML data available for report generation.\"",
     "        ",
     "        # Generate ML statistics",
     "        high_prob_motifs = ml_enhanced_df[ml_enhanced_df['ML_Formation_Probability'] > 0.7]",
     "        ",
     "        report = f\"\"\"",
     "# Machine Learning Analysis Report",
     "",
     "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
     "",
     "## ML Prediction Summary",
     "",
     "- **Total Motifs Analyzed:** {len(ml_enhanced_df)}",
     "- **High Formation Probability (>0.7):** {len(high_prob_motifs)} ({len(high_prob_motifs)/len(ml_enhanced_df)*100:.1f}%)",
     "- **Average Formation Probability:** {ml_enhanced_df['ML_Formation_Probability'].mean():.3f}",
     "- **Average Stability Score:** {ml_enhanced_df['ML_Stability_Score'].mean():.3f}",
     "",
     "## Top Predicted Motifs by Formation Probability",
     "",
     "\"\"\"",
     "        ",
     "        # Add top motifs",
     "        top_motifs = ml_enhanced_df.nlargest(10, 'ML_Formation_Probability')",
     "        for _, motif in top_motifs.iterrows():",
     "            report += f\"\"\"",
     "- **{motif.get('Class', 'Unknown')}** at {motif.get('Start', 0)}-{motif.get('End', 0)}",
     "  - Formation Probability: {motif['ML_Formation_Probability']:.3f}",
     "  - Stability Score: {motif['ML_Stability_Score']:.3f}",
     "  - Sequence: {motif.get('Sequence', '')[:50]}...",
     "",
     "\"\"\"",
     "        ",
     "        return report",
     "",
     "# Initialize ML analysis module",
     "ml_analyzer = MLMotifAnalysis()",
     "print(\"\u2705 Machine learning analysis module initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 9. Conservation and Evolutionary Analysis",
     "",
     "### \ud83e\uddec Sequence Conservation and Evolutionary Context",
     "",
     "Analyze sequence conservation and evolutionary significance of detected motifs."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class ConservationAnalysis:",
     "    \"\"\"Conservation and evolutionary analysis module\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.conservation_databases = {",
     "            'vertebrates': {'phylogeny_weight': 1.0, 'divergence_time': 500},",
     "            'mammals': {'phylogeny_weight': 0.8, 'divergence_time': 100},",
     "            'primates': {'phylogeny_weight': 0.6, 'divergence_time': 25}",
     "        }",
     "    ",
     "    def calculate_conservation_score(self, sequence: str, motif_class: str) -> float:",
     "        \"\"\"Calculate conservation score for a sequence\"\"\"",
     "        ",
     "        # Base conservation score",
     "        base_score = 0.5",
     "        ",
     "        # Adjust based on motif class (some are more conserved)",
     "        class_conservation = {",
     "            'G-Quadruplex': 0.8,",
     "            'R-loop': 0.7,",
     "            'Z-DNA': 0.6,",
     "            'Cruciform': 0.6,",
     "            'Curved DNA': 0.5,",
     "            'Triplex': 0.7,",
     "            'i-motif': 0.6",
     "        }",
     "        ",
     "        base_score = class_conservation.get(motif_class, 0.5)",
     "        ",
     "        # Sequence-based adjustments",
     "        gc_content_val = gc_content(sequence)",
     "        ",
     "        # High GC content often indicates conservation",
     "        if gc_content_val > 60:",
     "            base_score += 0.1",
     "        elif gc_content_val < 30:",
     "            base_score -= 0.1",
     "        ",
     "        # Palindromic sequences are often more conserved",
     "        if self._is_palindromic_region(sequence):",
     "            base_score += 0.15",
     "        ",
     "        # Repetitive sequences may be less conserved",
     "        if self._has_high_repetitive_content(sequence):",
     "            base_score -= 0.1",
     "        ",
     "        return min(1.0, max(0.0, base_score))",
     "    ",
     "    def _is_palindromic_region(self, sequence: str) -> bool:",
     "        \"\"\"Check if sequence has palindromic characteristics\"\"\"",
     "        # Check for palindromes of length 6 or more",
     "        for i in range(len(sequence) - 5):",
     "            for j in range(i + 6, min(i + 21, len(sequence) + 1)):",
     "                subseq = sequence[i:j]",
     "                if subseq == reverse_complement(subseq):",
     "                    return True",
     "        return False",
     "    ",
     "    def _has_high_repetitive_content(self, sequence: str) -> bool:",
     "        \"\"\"Check if sequence has high repetitive content\"\"\"",
     "        # Simple repetitive content check",
     "        for repeat_len in [2, 3, 4]:",
     "            for i in range(len(sequence) - repeat_len * 3):",
     "                pattern = sequence[i:i+repeat_len]",
     "                if sequence[i:i+repeat_len*4] == pattern * 4:",
     "                    return True",
     "        return False",
     "    ",
     "    def analyze_motif_conservation(self, motifs_df: pd.DataFrame) -> pd.DataFrame:",
     "        \"\"\"Analyze conservation for all motifs\"\"\"",
     "        ",
     "        if motifs_df.empty:",
     "            print(\"\u274c No motifs for conservation analysis\")",
     "            return motifs_df",
     "        ",
     "        print(\"\ud83e\uddec Analyzing sequence conservation...\")",
     "        ",
     "        conservation_scores = []",
     "        evolutionary_significance = []",
     "        ",
     "        for _, motif in motifs_df.iterrows():",
     "            sequence = motif.get('Sequence', '')",
     "            motif_class = motif.get('Class', '')",
     "            ",
     "            # Calculate conservation score",
     "            cons_score = self.calculate_conservation_score(sequence, motif_class)",
     "            conservation_scores.append(cons_score)",
     "            ",
     "            # Determine evolutionary significance",
     "            if cons_score > 0.8:",
     "                significance = 'Highly Conserved'",
     "            elif cons_score > 0.6:",
     "                significance = 'Moderately Conserved'",
     "            elif cons_score > 0.4:",
     "                significance = 'Weakly Conserved'",
     "            else:",
     "                significance = 'Not Conserved'",
     "            ",
     "            evolutionary_significance.append(significance)",
     "        ",
     "        # Add conservation data to dataframe",
     "        motifs_df = motifs_df.copy()",
     "        motifs_df['Conservation_Score'] = conservation_scores",
     "        motifs_df['Evolutionary_Significance'] = evolutionary_significance",
     "        ",
     "        # Calculate additional evolutionary metrics",
     "        motifs_df['Phylogenetic_Weight'] = [",
     "            self._calculate_phylogenetic_weight(score) for score in conservation_scores",
     "        ]",
     "        ",
     "        print(f\"\u2705 Conservation analysis complete for {len(motifs_df)} motifs\")",
     "        print(f\"   Highly conserved motifs: {sum(1 for sig in evolutionary_significance if sig == 'Highly Conserved')}\")",
     "        print(f\"   Average conservation score: {np.mean(conservation_scores):.3f}\")",
     "        ",
     "        return motifs_df",
     "    ",
     "    def _calculate_phylogenetic_weight(self, conservation_score: float) -> float:",
     "        \"\"\"Calculate phylogenetic weight based on conservation\"\"\"",
     "        # Higher conservation = higher phylogenetic weight",
     "        return conservation_score ** 2",
     "    ",
     "    def create_conservation_report(self, conservation_df: pd.DataFrame) -> str:",
     "        \"\"\"Create conservation analysis report\"\"\"",
     "        ",
     "        if conservation_df.empty or 'Conservation_Score' not in conservation_df.columns:",
     "            return \"No conservation data available for report generation.\"",
     "        ",
     "        # Generate conservation statistics",
     "        highly_conserved = conservation_df[conservation_df['Conservation_Score'] > 0.8]",
     "        ",
     "        report = f\"\"\"",
     "# Conservation and Evolutionary Analysis Report",
     "",
     "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
     "",
     "## Conservation Summary",
     "",
     "- **Total Motifs Analyzed:** {len(conservation_df)}",
     "- **Highly Conserved (>0.8):** {len(highly_conserved)} ({len(highly_conserved)/len(conservation_df)*100:.1f}%)",
     "- **Average Conservation Score:** {conservation_df['Conservation_Score'].mean():.3f}",
     "- **Conservation Range:** {conservation_df['Conservation_Score'].min():.3f} - {conservation_df['Conservation_Score'].max():.3f}",
     "",
     "## Conservation by Motif Class",
     "",
     "\"\"\"",
     "        ",
     "        # Add conservation by class",
     "        class_conservation = conservation_df.groupby('Class')['Conservation_Score'].agg(['mean', 'count']).round(3)",
     "        for motif_class, stats in class_conservation.iterrows():",
     "            report += f\"- **{motif_class}:** Average = {stats['mean']:.3f} (n={stats['count']})\\n\"",
     "        ",
     "        report += \"\\n## Most Conserved Motifs\\n\\n\"",
     "        ",
     "        # Add top conserved motifs",
     "        top_conserved = conservation_df.nlargest(10, 'Conservation_Score')",
     "        for _, motif in top_conserved.iterrows():",
     "            report += f\"\"\"",
     "- **{motif.get('Class', 'Unknown')}** at {motif.get('Start', 0)}-{motif.get('End', 0)}",
     "  - Conservation Score: {motif['Conservation_Score']:.3f}",
     "  - Evolutionary Significance: {motif['Evolutionary_Significance']}",
     "  - Sequence: {motif.get('Sequence', '')[:50]}...",
     "",
     "\"\"\"",
     "        ",
     "        return report",
     "",
     "# Initialize conservation analysis module",
     "conservation_analyzer = ConservationAnalysis()",
     "print(\"\u2705 Conservation analysis module initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 10. Export and Results Management",
     "",
     "### \ud83d\udcbe Multi-format Export and Data Management",
     "",
     "Comprehensive export capabilities for analysis results in multiple formats."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "class ResultsExportManager:",
     "    \"\"\"Comprehensive results export and management\"\"\"",
     "    ",
     "    def __init__(self):",
     "        self.supported_formats = ['csv', 'excel', 'json', 'txt', 'fasta']",
     "        ",
     "    def export_results(self, ",
     "                      results_df: pd.DataFrame, ",
     "                      filename_prefix: str = \"nbdfinder_results\",",
     "                      formats: List[str] = None,",
     "                      include_metadata: bool = True) -> Dict[str, str]:",
     "        \"\"\"Export results in multiple formats\"\"\"",
     "        ",
     "        if results_df.empty:",
     "            print(\"\u274c No results to export\")",
     "            return {}",
     "        ",
     "        if formats is None:",
     "            formats = ['csv', 'excel']",
     "        ",
     "        print(f\"\ud83d\udcbe Exporting results in {len(formats)} format(s)...\")",
     "        ",
     "        exported_files = {}",
     "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')",
     "        ",
     "        for format_type in formats:",
     "            if format_type not in self.supported_formats:",
     "                print(f\"\u26a0\ufe0f Unsupported format: {format_type}\")",
     "                continue",
     "            ",
     "            filename = f\"{filename_prefix}_{timestamp}.{format_type}\"",
     "            ",
     "            try:",
     "                if format_type == 'csv':",
     "                    results_df.to_csv(filename, index=False)",
     "                    exported_files['csv'] = filename",
     "                ",
     "                elif format_type == 'excel':",
     "                    with pd.ExcelWriter(filename, engine='openpyxl') as writer:",
     "                        # Main results",
     "                        results_df.to_excel(writer, sheet_name='Motif_Results', index=False)",
     "                        ",
     "                        # Summary statistics",
     "                        if include_metadata:",
     "                            summary_data = self._generate_summary_sheet(results_df)",
     "                            summary_df = pd.DataFrame(list(summary_data.items()), columns=['Metric', 'Value'])",
     "                            summary_df.to_excel(writer, sheet_name='Summary', index=False)",
     "                            ",
     "                            # Class distribution",
     "                            class_dist = results_df['Class'].value_counts().reset_index()",
     "                            class_dist.columns = ['Motif_Class', 'Count']",
     "                            class_dist.to_excel(writer, sheet_name='Class_Distribution', index=False)",
     "                    ",
     "                    exported_files['excel'] = filename",
     "                ",
     "                elif format_type == 'json':",
     "                    # Convert DataFrame to JSON with metadata",
     "                    export_data = {",
     "                        'export_info': {",
     "                            'timestamp': datetime.now().isoformat(),",
     "                            'total_motifs': len(results_df),",
     "                            'software': 'NBDFinder v2.0.0'",
     "                        },",
     "                        'motifs': results_df.to_dict('records')",
     "                    }",
     "                    ",
     "                    with open(filename, 'w') as f:",
     "                        json.dump(export_data, f, indent=2, default=str)",
     "                    ",
     "                    exported_files['json'] = filename",
     "                ",
     "                elif format_type == 'txt':",
     "                    # Create human-readable text report",
     "                    with open(filename, 'w') as f:",
     "                        f.write(self._generate_text_report(results_df))",
     "                    ",
     "                    exported_files['txt'] = filename",
     "                ",
     "                elif format_type == 'fasta':",
     "                    # Export motif sequences in FASTA format",
     "                    with open(filename, 'w') as f:",
     "                        for _, motif in results_df.iterrows():",
     "                            header = f\">{motif.get('Class', 'Unknown')}_{motif.get('Start', 0)}_{motif.get('End', 0)}\"",
     "                            if 'Analysis_Sequence' in motif:",
     "                                header += f\"_from_{motif['Analysis_Sequence']}\"",
     "                            f.write(f\"{header}\\n\")",
     "                            f.write(f\"{motif.get('Sequence', '')}\\n\")",
     "                    ",
     "                    exported_files['fasta'] = filename",
     "                ",
     "                print(f\"   \u2705 {format_type.upper()}: {filename}\")",
     "                ",
     "            except Exception as e:",
     "                print(f\"   \u274c Failed to export {format_type}: {e}\")",
     "        ",
     "        print(f\"\\n\ud83d\udcc1 Export complete: {len(exported_files)} files generated\")",
     "        return exported_files",
     "    ",
     "    def _generate_summary_sheet(self, df: pd.DataFrame) -> Dict:",
     "        \"\"\"Generate summary statistics for export\"\"\"",
     "        ",
     "        summary = {",
     "            'Total_Motifs': len(df),",
     "            'Unique_Classes': df['Class'].nunique(),",
     "            'Unique_Sequences': df['Analysis_Sequence'].nunique() if 'Analysis_Sequence' in df.columns else 1,",
     "            'Average_Motif_Length': df['Length'].mean() if 'Length' in df.columns else 0,",
     "            'Average_Score': df['Score'].mean() if 'Score' in df.columns else 0,",
     "            'Export_Timestamp': datetime.now().isoformat(),",
     "            'Software_Version': 'NBDFinder v2.0.0'",
     "        }",
     "        ",
     "        # Add class-specific counts",
     "        for motif_class, count in df['Class'].value_counts().items():",
     "            summary[f'Count_{motif_class.replace(\" \", \"_\").replace(\"-\", \"_\")}'] = count",
     "        ",
     "        return summary",
     "    ",
     "    def _generate_text_report(self, df: pd.DataFrame) -> str:",
     "        \"\"\"Generate human-readable text report\"\"\"",
     "        ",
     "        report = f\"\"\"",
     "NBDFinder Analysis Results Report",
     "================================",
     "",
     "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
     "Software: NBDFinder v2.0.0",
     "",
     "SUMMARY STATISTICS",
     "------------------",
     "Total Motifs Detected: {len(df)}",
     "Unique Motif Classes: {df['Class'].nunique()}",
     "Analyzed Sequences: {df['Analysis_Sequence'].nunique() if 'Analysis_Sequence' in df.columns else 1}",
     "",
     "MOTIF CLASS DISTRIBUTION",
     "-----------------------",
     "\"\"\"",
     "        ",
     "        # Add class distribution",
     "        for motif_class, count in df['Class'].value_counts().items():",
     "            percentage = (count / len(df)) * 100",
     "            report += f\"{motif_class}: {count} ({percentage:.1f}%)\\n\"",
     "        ",
     "        report += f\"\\nDETAILED MOTIF INFORMATION\\n\"",
     "        report += \"=\" * 50 + \"\\n\\n\"",
     "        ",
     "        # Add detailed motif information",
     "        for i, (_, motif) in enumerate(df.iterrows(), 1):",
     "            report += f\"Motif {i}:\\n\"",
     "            report += f\"  Class: {motif.get('Class', 'Unknown')}\\n\"",
     "            report += f\"  Position: {motif.get('Start', 0)}-{motif.get('End', 0)}\\n\"",
     "            report += f\"  Length: {motif.get('Length', 0)} bp\\n\"",
     "            report += f\"  Score: {motif.get('Score', 'N/A')}\\n\"",
     "            report += f\"  Sequence: {motif.get('Sequence', 'N/A')[:50]}...\\n\"",
     "            if 'Analysis_Sequence' in motif:",
     "                report += f\"  Source: {motif['Analysis_Sequence']}\\n\"",
     "            report += \"\\n\"",
     "        ",
     "        return report",
     "    ",
     "    def create_comprehensive_archive(self, ",
     "                                   results_df: pd.DataFrame,",
     "                                   clinical_df: pd.DataFrame = None,",
     "                                   conservation_df: pd.DataFrame = None,",
     "                                   archive_name: str = \"nbdfinder_complete_analysis\") -> str:",
     "        \"\"\"Create comprehensive analysis archive\"\"\"",
     "        ",
     "        import zipfile",
     "        ",
     "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')",
     "        archive_filename = f\"{archive_name}_{timestamp}.zip\"",
     "        ",
     "        print(f\"\ud83d\udce6 Creating comprehensive analysis archive...\")",
     "        ",
     "        with zipfile.ZipFile(archive_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:",
     "            # Export main results",
     "            main_files = self.export_results(results_df, \"main_analysis\", ['csv', 'excel', 'json'])",
     "            for file_path in main_files.values():",
     "                zipf.write(file_path)",
     "                os.remove(file_path)  # Clean up individual files",
     "            ",
     "            # Export clinical results if available",
     "            if clinical_df is not None and not clinical_df.empty:",
     "                clinical_files = self.export_results(clinical_df, \"clinical_analysis\", ['csv', 'excel'])",
     "                for file_path in clinical_files.values():",
     "                    zipf.write(file_path)",
     "                    os.remove(file_path)",
     "            ",
     "            # Export conservation results if available",
     "            if conservation_df is not None and not conservation_df.empty:",
     "                conservation_files = self.export_results(conservation_df, \"conservation_analysis\", ['csv'])",
     "                for file_path in conservation_files.values():",
     "                    zipf.write(file_path)",
     "                    os.remove(file_path)",
     "            ",
     "            # Add analysis metadata",
     "            metadata = {",
     "                'analysis_timestamp': datetime.now().isoformat(),",
     "                'software_version': 'NBDFinder v2.0.0',",
     "                'total_motifs': len(results_df),",
     "                'analysis_types': ['motif_detection'],",
     "                'export_formats': ['csv', 'excel', 'json']",
     "            }",
     "            ",
     "            if clinical_df is not None:",
     "                metadata['analysis_types'].append('clinical_analysis')",
     "            if conservation_df is not None:",
     "                metadata['analysis_types'].append('conservation_analysis')",
     "            ",
     "            # Write metadata",
     "            zipf.writestr('analysis_metadata.json', json.dumps(metadata, indent=2))",
     "        ",
     "        print(f\"\u2705 Comprehensive archive created: {archive_filename}\")",
     "        return archive_filename",
     "",
     "# Initialize export manager",
     "export_manager = ResultsExportManager()",
     "print(\"\u2705 Results export manager initialized\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 11. Complete Integrated Analysis Execution",
     "",
     "### \ud83d\ude80 Run Complete Comprehensive Analysis",
     "",
     "Execute the full NBDFinder analysis pipeline with all advanced features."
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Complete integrated analysis execution",
     "if seq_manager.sequences:",
     "    print(\"\ud83d\ude80 Starting COMPLETE NBDFinder analysis pipeline...\")",
     "    print(\"=\"*60)",
     "    ",
     "    # Step 1: Core motif detection (already done above)",
     "    if 'results_df' not in locals() or results_df.empty:",
     "        print(\"\\n1\ufe0f\u20e3 Running core motif detection...\")",
     "        results = analyzer.analyze_all_sequences(seq_manager)",
     "        results_df = analyzer.get_results_dataframe()",
     "    ",
     "    if not results_df.empty:",
     "        print(f\"\\n\u2705 Core analysis complete: {len(results_df)} motifs detected\")",
     "        ",
     "        # Step 2: Machine Learning Enhancement",
     "        print(\"\\n2\ufe0f\u20e3 Applying machine learning enhancement...\")",
     "        ml_enhanced_df = ml_analyzer.predict_motif_formation(results_df)",
     "        ",
     "        # Step 3: Conservation Analysis",
     "        print(\"\\n3\ufe0f\u20e3 Performing conservation analysis...\")",
     "        conservation_enhanced_df = conservation_analyzer.analyze_motif_conservation(ml_enhanced_df)",
     "        ",
     "        # Step 4: Clinical Analysis",
     "        print(\"\\n4\ufe0f\u20e3 Running clinical significance analysis...\")",
     "        clinical_results = clinical_module.analyze_clinical_significance(conservation_enhanced_df)",
     "        ",
     "        # Step 5: Bacterial Genome Analysis (if applicable)",
     "        bacterial_results = []",
     "        for seq, name in zip(seq_manager.sequences, seq_manager.sequence_names):",
     "            if len(seq) > 100000:  # Assume large sequences are genomes",
     "                print(f\"\\n5\ufe0f\u20e3 Analyzing bacterial genome characteristics for {name}...\")",
     "                bacterial_result = bacterial_analyzer.analyze_bacterial_sequence(seq, name)",
     "                bacterial_results.append(bacterial_result)",
     "        ",
     "        # Step 6: Generate comprehensive reports",
     "        print(\"\\n6\ufe0f\u20e3 Generating comprehensive reports...\")",
     "        ",
     "        # ML Report",
     "        ml_report = ml_analyzer.create_ml_report(ml_enhanced_df)",
     "        with open('ml_analysis_report.md', 'w') as f:",
     "            f.write(ml_report)",
     "        ",
     "        # Conservation Report",
     "        conservation_report = conservation_analyzer.create_conservation_report(conservation_enhanced_df)",
     "        with open('conservation_analysis_report.md', 'w') as f:",
     "            f.write(conservation_report)",
     "        ",
     "        # Clinical Report",
     "        clinical_report = clinical_module.generate_clinical_report(clinical_results)",
     "        with open('clinical_analysis_report.md', 'w') as f:",
     "            f.write(clinical_report)",
     "        ",
     "        # Step 7: Advanced Visualizations",
     "        print(\"\\n7\ufe0f\u20e3 Creating advanced visualizations...\")",
     "        ",
     "        # Core visualizations",
     "        viz_suite.plot_motif_distribution(conservation_enhanced_df)",
     "        viz_suite.plot_sequence_overview(conservation_enhanced_df, seq_manager)",
     "        ",
     "        # ML-specific visualizations",
     "        if 'ML_Formation_Probability' in conservation_enhanced_df.columns:",
     "            fig_ml = px.scatter(",
     "                conservation_enhanced_df,",
     "                x='ML_Formation_Probability',",
     "                y='Conservation_Score',",
     "                color='Class',",
     "                size='Length',",
     "                title=\"ML Formation Probability vs Conservation Score\",",
     "                hover_data=['Analysis_Sequence', 'Start', 'End']",
     "            )",
     "            fig_ml.show()",
     "        ",
     "        # Step 8: Comprehensive Export",
     "        print(\"\\n8\ufe0f\u20e3 Exporting comprehensive results...\")",
     "        ",
     "        # Export all analysis results",
     "        exported_files = export_manager.export_results(",
     "            conservation_enhanced_df,",
     "            \"comprehensive_analysis\",",
     "            formats=['csv', 'excel', 'json', 'txt', 'fasta']",
     "        )",
     "        ",
     "        # Create complete archive",
     "        archive_file = export_manager.create_comprehensive_archive(",
     "            conservation_enhanced_df,",
     "            clinical_results,",
     "            conservation_enhanced_df",
     "        )",
     "        ",
     "        # Final Summary",
     "        print(\"\\n\" + \"=\"*60)",
     "        print(\"\ud83c\udf89 COMPLETE ANALYSIS FINISHED!\")",
     "        print(\"=\"*60)",
     "        print(f\"\ud83d\udcca Final Results Summary:\")",
     "        print(f\"   \u2022 Total motifs detected: {len(conservation_enhanced_df):,}\")",
     "        print(f\"   \u2022 Motif classes found: {conservation_enhanced_df['Class'].nunique()}\")",
     "        print(f\"   \u2022 Sequences analyzed: {conservation_enhanced_df['Analysis_Sequence'].nunique()}\")",
     "        ",
     "        if 'ML_Formation_Probability' in conservation_enhanced_df.columns:",
     "            high_ml_prob = len(conservation_enhanced_df[conservation_enhanced_df['ML_Formation_Probability'] > 0.7])",
     "            print(f\"   \u2022 High ML formation probability: {high_ml_prob}\")",
     "        ",
     "        if 'Conservation_Score' in conservation_enhanced_df.columns:",
     "            highly_conserved = len(conservation_enhanced_df[conservation_enhanced_df['Conservation_Score'] > 0.8])",
     "            print(f\"   \u2022 Highly conserved motifs: {highly_conserved}\")",
     "        ",
     "        clinical_significant = len(clinical_results[clinical_results['Clinical_Significance'].isin(['Pathogenic', 'Likely Pathogenic'])])",
     "        print(f\"   \u2022 Clinically significant findings: {clinical_significant}\")",
     "        ",
     "        print(f\"\\n\ud83d\udcc1 Generated Files:\")",
     "        for format_type, filename in exported_files.items():",
     "            print(f\"   \u2022 {format_type.upper()}: {filename}\")",
     "        print(f\"   \u2022 Archive: {archive_file}\")",
     "        print(f\"   \u2022 Reports: ml_analysis_report.md, conservation_analysis_report.md, clinical_analysis_report.md\")",
     "        ",
     "        print(f\"\\n\ud83c\udfaf Analysis complete! All results exported and ready for use.\")",
     "        ",
     "        # Display final results table",
     "        print(f\"\\n\ud83d\udccb Final Enhanced Results (showing first 10 rows):\")",
     "        display_columns = ['Analysis_Sequence', 'Class', 'Start', 'End', 'Length', 'Score']",
     "        if 'ML_Formation_Probability' in conservation_enhanced_df.columns:",
     "            display_columns.append('ML_Formation_Probability')",
     "        if 'Conservation_Score' in conservation_enhanced_df.columns:",
     "            display_columns.append('Conservation_Score')",
     "        ",
     "        display(conservation_enhanced_df[display_columns].head(10))",
     "        ",
     "    else:",
     "        print(\"\u274c No motifs detected in the analysis\")",
     "",
     "else:",
     "    print(\"\u274c No sequences loaded for analysis\")",
     "    print(\"\ud83d\udca1 Please load sequences using the sections above before running the complete analysis.\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 12. Usage Examples and Educational Content",
     "",
     "### \ud83d\udcda Comprehensive Usage Examples",
     "",
     "This section provides detailed examples for different analysis scenarios.",
     "",
     "#### Example 1: Basic Motif Detection",
     "```python",
     "# Load a sequence",
     "sequence = \"TTAGGGTTAGGGTTAGGGTTAGGG\"",
     "seq_manager.add_sequence(sequence, \"Telomere_Example\")",
     "",
     "# Run basic analysis",
     "results = analyzer.analyze_all_sequences(seq_manager)",
     "```",
     "",
     "#### Example 2: Clinical Analysis Focus",
     "```python",
     "# For clinical analysis, focus on disease-associated repeats",
     "clinical_sequence = \"GAAGAAGAAGAA\" * 20  # Friedreich's ataxia repeat",
     "seq_manager.add_sequence(clinical_sequence, \"Clinical_Test\")",
     "",
     "# Run with clinical focus",
     "results = analyzer.analyze_all_sequences(seq_manager, include_disease=True)",
     "clinical_analysis = clinical_module.analyze_clinical_significance(results_df)",
     "```",
     "",
     "#### Example 3: Bacterial Genome Analysis",
     "```python",
     "# For bacterial genomes, use comparative analysis",
     "bacterial_seq = \"ATCGATCG\" * 1000  # Example bacterial sequence",
     "bacterial_result = bacterial_analyzer.analyze_bacterial_sequence(bacterial_seq, \"E_coli_test\")",
     "```",
     "",
     "#### Example 4: Visualization Focus",
     "```python",
     "# Generate specific visualizations",
     "viz_suite.plot_motif_distribution(results_df)",
     "viz_suite.plot_motif_locations(results_df, sequence_name=\"specific_sequence\")",
     "```",
     "",
     "#### Example 5: Export Results",
     "```python",
     "# Export in multiple formats",
     "export_manager.export_results(results_df, \"my_analysis\", formats=['csv', 'excel', 'json'])",
     "```",
     "",
     "### \ud83d\udd2c Scientific Background",
     "",
     "#### Non-B DNA Structures Overview",
     "",
     "1. **G-Quadruplexes**: Four-stranded structures formed by guanine-rich sequences",
     "2. **Z-DNA**: Left-handed double helix formed by alternating purines and pyrimidines",
     "3. **Cruciform DNA**: Four-way junction structures from palindromic sequences",
     "4. **R-loops**: Three-stranded structures with RNA-DNA hybrids",
     "5. **Triplex DNA**: Three-stranded structures with Hoogsteen base pairing",
     "",
     "### \ud83d\udcd6 Best Practices",
     "",
     "1. **Sequence Quality**: Ensure sequences are clean and properly formatted",
     "2. **Parameter Selection**: Adjust analysis parameters based on sequence type",
     "3. **Result Validation**: Cross-validate important findings with experimental data",
     "4. **Clinical Use**: Always validate clinical findings with appropriate testing",
     "5. **Data Management**: Keep detailed records of analysis parameters and versions",
     "",
     "### \ud83d\ude80 Advanced Tips",
     "",
     "- Use parallel processing for large sequence sets",
     "- Combine multiple analysis types for comprehensive results",
     "- Regularly update to latest NBDFinder version",
     "- Validate findings with literature and experimental data",
     "- Consider sequence context and biological relevance"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 13. Troubleshooting and FAQ",
     "",
     "### \u2753 Frequently Asked Questions",
     "",
     "#### Q: No motifs detected in my sequence",
     "**A:** This could be due to:",
     "- Sequence too short (< 20 bp recommended)",
     "- Low complexity sequence",
     "- Sequence doesn't contain non-B DNA forming patterns",
     "- Try adjusting analysis parameters",
     "",
     "#### Q: High memory usage during analysis",
     "**A:** For large sequences:",
     "- Process sequences individually",
     "- Use chunked processing for very long sequences",
     "- Close other applications to free memory",
     "",
     "#### Q: Export functions not working",
     "**A:** Check:",
     "- File permissions in current directory",
     "- Available disk space",
     "- Required packages (openpyxl, xlsxwriter) installed",
     "",
     "#### Q: Visualization figures not displaying",
     "**A:** Ensure:",
     "- matplotlib and plotly are installed",
     "- Jupyter notebook properly configured for plots",
     "- Try `%matplotlib inline` if needed",
     "",
     "#### Q: NCBI fetching fails",
     "**A:** Check:",
     "- Internet connection",
     "- BioPython installation",
     "- Valid accession numbers",
     "- NCBI server availability",
     "",
     "### \ud83d\udd27 Troubleshooting Steps",
     "",
     "1. **Import Errors**: Verify all required packages are installed",
     "2. **Memory Issues**: Process smaller chunks or individual sequences",
     "3. **Slow Performance**: Use parallel processing for multiple sequences",
     "4. **File Errors**: Check file paths and permissions",
     "5. **Analysis Errors**: Validate input sequence format and content",
     "",
     "### \ud83d\udcde Support and Resources",
     "",
     "- **GitHub Repository**: https://github.com/VRYella/NBDFinder",
     "- **Documentation**: See README.md and documentation files",
     "- **Issues**: Report bugs on GitHub issues page",
     "- **Contact**: Dr. Venkata Rajesh Yella",
     "",
     "### \ud83d\udd04 Version Information",
     "",
     "**Current Version**: NBDFinder v2.0.0",
     "**Notebook Version**: Complete Analysis v1.0",
     "**Last Updated**: 2024",
     "",
     "### \ud83d\udccb System Requirements",
     "",
     "- **Python**: 3.8 or higher",
     "- **Memory**: 4GB RAM minimum (8GB+ recommended for large genomes)",
     "- **Storage**: 1GB free space for results and exports",
     "- **Dependencies**: See requirements.txt"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 14. Conclusion and Next Steps",
     "",
     "### \ud83c\udf89 Congratulations!",
     "",
     "You have successfully completed the comprehensive NBDFinder analysis pipeline. This notebook provides:",
     "",
     "\u2705 **Complete motif detection** across all 10 non-B DNA categories  ",
     "\u2705 **Advanced visualizations** with publication-quality plots  ",
     "\u2705 **Clinical analysis** with disease association and ACMG guidelines  ",
     "\u2705 **Machine learning integration** for enhanced predictions  ",
     "\u2705 **Conservation analysis** for evolutionary context  ",
     "\u2705 **Bacterial genome analysis** for comparative genomics  ",
     "\u2705 **Multi-format exports** for data sharing and publication  ",
     "",
     "### \ud83d\ude80 Next Steps",
     "",
     "1. **Validate Results**: Cross-check important findings with experimental data",
     "2. **Publication**: Use generated visualizations and reports for manuscripts",
     "3. **Clinical Application**: Follow up on significant clinical findings",
     "4. **Extended Analysis**: Apply to larger datasets or different species",
     "5. **Method Development**: Contribute improvements back to NBDFinder",
     "",
     "### \ud83d\udcda Citation",
     "",
     "If you use NBDFinder in your research, please cite:",
     "",
     "```",
     "NBDFinder: Comprehensive Non-B DNA Motif Detection Platform",
     "Dr. Venkata Rajesh Yella",
     "Version 2.0.0 (2024)",
     "GitHub: https://github.com/VRYella/NBDFinder",
     "```",
     "",
     "### \ud83d\udd2c Scientific Impact",
     "",
     "Non-B DNA structures play crucial roles in:",
     "- **Gene regulation and expression**",
     "- **Genomic instability and disease**",
     "- **DNA replication and repair**",
     "- **Evolutionary processes**",
     "- **Therapeutic targeting**",
     "",
     "Your analysis contributes to understanding these important biological processes.",
     "",
     "### \ud83d\ude4f Acknowledgments",
     "",
     "- **NBDFinder Development Team**",
     "- **Scientific Community** for validation and feedback",
     "- **Open Source Contributors** for essential packages",
     "- **Research Institutions** supporting this work",
     "",
     "---",
     "",
     "**Happy Analyzing! \ud83e\uddec\ud83d\udcca**",
     "",
     "*This notebook represents the complete NBDFinder analysis platform. For updates and improvements, visit the GitHub repository.*"
    ]
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}